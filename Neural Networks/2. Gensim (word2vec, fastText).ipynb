{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Обучение модели word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gensim** &ndash; библиотека для обработки и векторного представления текстов, в которой реализованы также модели word2vec и fastText. Для демонстрации принципов работы с моделью word2vec в gensim воспользуемся небольшим корпусом текстов `common_texts` из модуля `gensim.test.utils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение производится через вызов функции `Word2Vec`, первым аргументом которой является набор текстов, параметр `vector_size` задает размер эмбеддингов, `window` определяет ширину окна при формировании контекстных слов, `min_count` позволяет учитывать только те слова, которые встретились в корпусе не менее определенного количества раз (в примере не менее двух)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(common_texts, vector_size=20, window=3, min_count=2, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если не указать корпус текстов в модели, то обучение модели производится через метод `train` после вызова функции `build_vocab`, где в качестве аргумента используется корпус. Такой подход позволяет позже дообучать модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(vector_size=20, window=3, min_count=2)\n",
    "model.build_vocab(common_texts)\n",
    "model.train(common_texts, total_examples=len(common_texts), epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обучения можно получить векторное представление для каждого из слов корпуса, а также вывести наиболее близкие к ним слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('computer', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели `fastText` производится аналогичным образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(common_texts, vector_size=4, window=3, min_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "или"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(vector_size=4, window=3, min_count=2)\n",
    "model.build_vocab(common_texts)\n",
    "model.train(common_texts, total_examples=len(common_texts), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('computer', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Загрузка предобученных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim позволяет загружать предобученные вектора. Список доступных предобученных моделей доступен в `gensim.downloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors.most_similar('computer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобученные вектора слов можно использовать в моделях PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_vectors = gensim.downloader.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor(fasttext_vectors.vectors)\n",
    "# embedding = nn.Embedding.from_pretrained(weights)\n",
    "# embedding.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, n_classes, matrix_embeddings):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.hidden_dim = 512\n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(matrix_embeddings)\n",
    "        self.embeddings.requires_grad = False\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_dim, self.n_classes))\n",
    "        \n",
    "    def forward(self, input_sentence):\n",
    "        u = self.embeddings(input_sentence)\n",
    "        return self.classifier(u)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
